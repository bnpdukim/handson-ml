##CHAPTER 1 한눈에 보는 머신러닝
* 머신러닝은 어디서 시작하고 어디서 끝나는가?
* 기계가 배운다는 것이 정확히 무슨 의미인가?
* 위키백과 문서를 내려받으면 컴퓨터가 실제로 무언가를 배울수 있는가?
* 컴퓨터가 갑자기 똑똑해 질수 있는가?
* 머신러닝이 무엇이며 왜 필요한가?
###1.1 머신러닝이란?
* 정의 1
  - 데이터로부터 학습하도록 컴퓨터를 프로그램하는 과학
* 정의 2
  - 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야
* 정의 3
  - 작업 T에 대해 성능을 P로 축정했을 때 경험 E로 인해 성능이 향상 됐다면,
  이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것
  - ex> 스팸필터
    - 작업 T : 메일이 스팸인지 구분하는 것
    - 경험 E : 훈련 데이터
    - 성능 측정 P : 정확도
###1.2 왜 머신러닝을 사용하는가?
* 그림 1-1
  - 규칙이 점점 길고 복잡해짐
  - 유지보수하기 힘듬
* 그림 1-2
  - 패턴 감지
  - 자동 학습
* 머신러닝이 뛰어난 분야
  - 많은 조정과 규칙이 필요한 문제
  - 전통적인 방식으로는 해결할 수 없는 복잡한 문제
    - 음성인식
  - 유동적 환경
    - 새로운 데이터에 적응
  - 복잡한 문제와 대량의 데이터에서 통찰 얻기
###1.3 머신러닝 시스템의 종류
* 학습법에 따른 분류
  - 지도, 비지도, 준지도, 강화 학습
* 점진적 학습 여부에 따른 분류
  - 배치 학습 vs 온라인 학습
* 어떻게 일반화되는가에 따른 분류
  - 사례 기반 학습 vs 모델 기반 학습
####1.3.1 지도 학습과 비지도 학습
* 지도 학습(supervised learning)
  - 훈련 데이터에 정답(레이블)이 포함되어 있음
  - 분류(classification)와 회귀(regression)가 대표적인 작업
  -  학습 알고리즘
    - k-최근접 이웃(K-Nearest Neighbors)
    - 선형 회귀(Linear Regression)
    - 로지스틱 회귀(Logistic Regression)
    - 서포트 벡터 머신(Support Vector Machines:SVM)
    - 신경망(Neural Networks)
* 비지도 학습(unsupervised learning)
  - 훈련 데이터에 레이블이 없는 상태에서 학습
  - 학습 알고리즘
    - 군집(clustering)
      - k-평균(k-Means)
      - 계층 군집 분석
      - 기대값 최대화
    - 시각화(visualization)와 차원 축소(dimensionality reduction)
      - 주성분 분석(Principal Component Analysis:PCA)
      - 커널 PCA
      - 지역적 선형 임베딩(LLE)
      - t-SNE
    - 연관 규칙 학습
      - 어프라이어리
      - 이클렛
  - 계층 군집(hierarchical clustering)
    - 그룹을 더 작은 그룹으로 세분화
  - 시각화(visualization)
    - 레이블이 없는 대규모의 고차원 데이터를 넣으면 도식화가 가능한 2D나 3D 표현을 만듬
    - 차원 축소
      - 많은 정보를 잃지 않으면서 데이터 간소화
      - 상관관계가 있는 여러 특성을 하나로 합침
        - 특성 추출이라 부름
        - 훈련 데이터의 차원을 줄임으로써 성능 향상을 가져옴
  - 이상치 탐지
    - 학습 알고리즘 주입전에 데이터셋에서 이상한 값을 자동으로 제거
    - ex> 신용카드 부정 거래 감지
  - 연관 규칙 학습
    - 특성 간의 흥미로운 관계를 찾음
* 준지도 학습(semisupervised learning)
  - 보통 레이블이 없는 데이터가 많고 레이블이 있는 데이터는 아주 조금
  - ex> 구글 포토 호스팅
* 강화 학습(reinforcement learning)
  - 그림 1-12
  1. 관찰
  2. 정책에 따라 행동을 선택
  3. 행동 실행
  4. 보상이나 벌점을 받음
  5. 정책 수정(학습 단계)
  6. 최적의 정책을 찾을 때까지 반복
  - ex> 딥마인드의  알파고
####1.3.2 배치 학습과 온라인 학습
* 배치 학습(batch learning)
  - 가용한 데이터를 모두 사용해 훈련
  - 시스템을 훈련시키고 제품에 적용하면 학습없이 실행
    - 오프라인 학습
    - Nvidia - Jetson Nano
      - https://www.nvidia.com/ko-kr/autonomous-machines/embedded-systems/jetson-nano/
    - Google - Coral
      - https://coral.withgoogle.com/products/
* 온라인 학습(online learning)
  - 데이터를 순차적으로 작은 묶음 단위로 주입하여 훈련
  - 연속적으로 데이터를 받고 빠른 변화에 스스로 적응하는 시스템에 적합
    - ex> 주식 가격 예측
  - 메인 메모리에 들어갈 수 없는 아주 큰 데이터셋을 학습하는 시스템에도 사용
    - 외부 메모리 학습
    - 실시간 시스템에서 수행되는 것이 아님
      - 이럴경우 온라인 학습보다는 점진적 학습이 더 어울림
  - 변화하는 데이터에 얼마나 빠르게 적응할지를 나타내는 학습률이 중요한 파라미터임
  - 나쁜 데이터가 주입되었을 때 시스템 성능이 점진적으로 감소
    - 금융과 딥러닝
      - https://www.youtube.com/watch?v=dB8cpsnZ5FA&app=desktop    
####1.3.3 사례 기반 학습과 모델 기반 학습
* 사례 기반 학습
  - 시스템이 사례를 기억함으로써 학습
* 모델 기반 학습
  - 샘플들의 모델을 만들어 예측에 사용
  - ex> 돈이 사람을 행복하게 만드는가?
    - 표 1-1, 그림 1-17 참고
    - 모델 선택
      - 삶의 만족도는 GDP가 증가할수록 선형으로 올라감
      - 삶의 만족도 = Θ0 + Θ1 * 1인당GDP
      - 모델 파라미터를 조절함으로써 그림 1-18처럼 다양한 선형 모델 표현 가능
    - 효용 함수(적합도 함수)
      - 모델이 얼마나 좋은지 측정하는 함수
    - 비용 함수
      - 모델이 얼마나 나쁜지 측정하는 함수
    - 선형회귀에서는 모델의 예측과 훈련 데이터 사이의 거리를 재는 비용 함수를 사용
      - 거리를 최소화하는 것이 목표
      - 데이터에 가장 잘 맞는 선형 모델의 파라미터를 찾음
        - 모델을 훈련(training) 시킨다라고 표현함
###1.4 머신러닝의 주요 도전 과제
####1.4.1 충분하지 않은 양의 훈련 데이터
####1.4.2 대표성 없는 훈련 데이터
####1.4.3 낮은 품질의 데이터
####1.4.4 관련 없는 특성
####1.4.5 훈련 데이터 과대적합
####1.4.6 훈련 데이터 과소적합
####1.4.7 한걸음 물러서서
###1.5 테스트와 검증
###1.6 연습문제