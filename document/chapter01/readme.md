##CHAPTER 1 한눈에 보는 머신러닝
* 머신러닝은 어디서 시작하고 어디서 끝나는가?
* 기계가 배운다는 것이 정확히 무슨 의미인가?
* 위키백과 문서를 내려받으면 컴퓨터가 실제로 무언가를 배울수 있는가?
* 컴퓨터가 갑자기 똑똑해 질수 있는가?
* 머신러닝이 무엇이며 왜 필요한가?

###1.1 머신러닝이란?
* 정의 1
  - 데이터로부터 학습하도록 컴퓨터를 프로그램하는 과학
* 정의 2
  - 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야
* 정의 3
  - 작업 T에 대해 성능을 P로 축정했을 때 경험 E로 인해 성능이 향상 됐다면,
  이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것
  - ex> 스팸필터
    - 작업 T : 메일이 스팸인지 구분하는 것
    - 경험 E : 훈련 데이터
    - 성능 측정 P : 정확도

###1.2 왜 머신러닝을 사용하는가?
* 그림 1-1
  - 규칙이 점점 길고 복잡해짐
  - 유지보수하기 힘듬
* 그림 1-2
  - 패턴 감지
  - 자동 학습
* 머신러닝이 뛰어난 분야
  - 많은 조정과 규칙이 필요한 문제
  - 전통적인 방식으로는 해결할 수 없는 복잡한 문제
    - 음성인식
  - 유동적 환경
    - 새로운 데이터에 적응
  - 복잡한 문제와 대량의 데이터에서 통찰 얻기

###1.3 머신러닝 시스템의 종류
* 학습법에 따른 분류
  - 지도, 비지도, 준지도, 강화 학습
* 점진적 학습 여부에 따른 분류
  - 배치 학습 vs 온라인 학습
* 어떻게 일반화되는가에 따른 분류
  - 사례 기반 학습 vs 모델 기반 학습

####1.3.1 지도 학습과 비지도 학습
* 지도 학습(supervised learning)
  - 훈련 데이터에 정답(레이블)이 포함되어 있음
  - 분류(classification)와 회귀(regression)가 대표적인 작업
  -  학습 알고리즘
    - k-최근접 이웃(K-Nearest Neighbors)
    - 선형 회귀(Linear Regression)
    - 로지스틱 회귀(Logistic Regression)
    - 서포트 벡터 머신(Support Vector Machines:SVM)
    - 신경망(Neural Networks)
* 비지도 학습(unsupervised learning)
  - 훈련 데이터에 레이블이 없는 상태에서 학습
  - 학습 알고리즘
    - 군집(clustering)
      - k-평균(k-Means)
      - 계층 군집 분석
      - 기대값 최대화
    - 시각화(visualization)와 차원 축소(dimensionality reduction)
      - 주성분 분석(Principal Component Analysis:PCA)
      - 커널 PCA
      - 지역적 선형 임베딩(LLE)
      - t-SNE
    - 연관 규칙 학습
      - 어프라이어리
      - 이클렛
  - 계층 군집(hierarchical clustering)
    - 그룹을 더 작은 그룹으로 세분화
  - 시각화(visualization)
    - 레이블이 없는 대규모의 고차원 데이터를 넣으면 도식화가 가능한 2D나 3D 표현을 만듬
    - 차원 축소
      - 많은 정보를 잃지 않으면서 데이터 간소화
      - 상관관계가 있는 여러 특성을 하나로 합침
        - 특성 추출이라 부름
        - 훈련 데이터의 차원을 줄임으로써 성능 향상을 가져옴
  - 이상치 탐지
    - 학습 알고리즘 주입전에 데이터셋에서 이상한 값을 자동으로 제거
    - ex> 신용카드 부정 거래 감지
  - 연관 규칙 학습
    - 특성 간의 흥미로운 관계를 찾음
* 준지도 학습(semisupervised learning)
  - 보통 레이블이 없는 데이터가 많고 레이블이 있는 데이터는 아주 조금
  - ex> 구글 포토 호스팅
* 강화 학습(reinforcement learning)
  - 그림 1-12
  1. 관찰
  2. 정책에 따라 행동을 선택
  3. 행동 실행
  4. 보상이나 벌점을 받음
  5. 정책 수정(학습 단계)
  6. 최적의 정책을 찾을 때까지 반복
  - ex> 딥마인드의  알파고

####1.3.2 배치 학습과 온라인 학습
* 배치 학습(batch learning)
  - 가용한 데이터를 모두 사용해 훈련
  - 시스템을 훈련시키고 제품에 적용하면 학습없이 실행
    - 오프라인 학습
    - Nvidia - Jetson Nano
      - https://www.nvidia.com/ko-kr/autonomous-machines/embedded-systems/jetson-nano/
    - Google - Coral
      - https://coral.withgoogle.com/products/
* 온라인 학습(online learning)
  - 데이터를 순차적으로 작은 묶음 단위로 주입하여 훈련
  - 연속적으로 데이터를 받고 빠른 변화에 스스로 적응하는 시스템에 적합
    - ex> 주식 가격 예측
  - 메인 메모리에 들어갈 수 없는 아주 큰 데이터셋을 학습하는 시스템에도 사용
    - 외부 메모리 학습
    - 실시간 시스템에서 수행되는 것이 아님
      - 이럴경우 온라인 학습보다는 점진적 학습이 더 어울림
  - 변화하는 데이터에 얼마나 빠르게 적응할지를 나타내는 학습률이 중요한 파라미터임
  - 나쁜 데이터가 주입되었을 때 시스템 성능이 점진적으로 감소
    - 금융과 딥러닝
      - https://www.youtube.com/watch?v=dB8cpsnZ5FA&app=desktop    

####1.3.3 사례 기반 학습과 모델 기반 학습
* 사례 기반 학습
  - 시스템이 사례를 기억함으로써 학습
* 모델 기반 학습
  - 샘플들의 모델을 만들어 예측에 사용
  - ex> 돈이 사람을 행복하게 만드는가?
    - 표 1-1, 그림 1-17 참고
    - 모델 선택
      - 삶의 만족도는 GDP가 증가할수록 선형으로 올라감
      - 삶의 만족도 = Θ0 + Θ1 * 1인당GDP
      - 모델 파라미터를 조절함으로써 그림 1-18처럼 다양한 선형 모델 표현 가능
    - 효용 함수(적합도 함수)
      - 모델이 얼마나 좋은지 측정하는 함수
    - 비용 함수
      - 모델이 얼마나 나쁜지 측정하는 함수
    - 선형회귀에서는 모델의 예측과 훈련 데이터 사이의 거리를 재는 비용 함수를 사용
      - 거리를 최소화하는 것이 목표
      - 데이터에 가장 잘 맞는 선형 모델의 파라미터를 찾음
        - 모델을 훈련(training) 시킨다라고 표현함

###1.4 머신러닝의 주요 도전 과제
* 나쁜 알고리즘
* 나쁜 데이터

####1.4.1 충분하지 않은 양의 훈련 데이터

####1.4.2 대표성 없는 훈련 데이터
* 일반화하기 원하는 사례를 훈련 데이터가 잘 대표해야함
* 샘플이 작으면 샘플링 잡음(sampling noise)이 생김
* 표본 추출 방법이 잘못되면 대표성을 띠지 못함(샘플링 편향 : sampling bias)
  - 1936 미국 대통령 선거
    - 소수의 응답자 의견을 받고 대통령 예측 

####1.4.3 낮은 품질의 데이터
* 훈련 데이터가 에러, 이상치, 잡음으로 가득하면 내재된 패턴 도출이 힘듬
  - 데이터 정제에 시간 투자해야함

####1.4.4 관련 없는 특성
* 관련 없는 특성이 적고 관련 있는 특성이 충분해야 함
* 특성 선택(feature selection)
  - 훈련에 유용한 특성 선택
* 특성 추출(feature extraction)
  - 특성을 결합하여 더 유용한 특성을 만듬(차원 축소 알고르즘 사용)

####1.4.5 훈련 데이터 과대적합
* 훈련 데이터에 너무 잘 맞지만 일반성이 떨어짐
  - 새로운 샘플에 일반화 되지 못함
  - 해결방법
    - 파라미터 수가 적은 모델을 선택
    - 특성수를 줄이거나 모델에 제약을 가하여 단순화
    - 훈련 데이터를 더 많이 모음
    - 훈련 데이터의 잡음을 줄임
  - 규제(regularization)
    - 모델을 단순하게 하고 과대적합의 위험을 감소시키기 위해 모델에 제약을 가하는 것
    - 삶의 만족도 = Θ0 + Θ1 * 1인당GDP 에 규제 적용하기
    1. Θ1 = 0이 되도록 강제
      - 평균이 되므로 제대로된 모델이 안 만들어짐
    2. Θ1을 수정하되 작은 값을 갖도록 유지
      - 그림 1-23 참고
    - 학습하는 동안 적용할 규제의 양은 하이퍼파라미터(hyperparameter)가 결정
      - 훈련 전에 미리 지정되고, 훈련하는 동안에는 상수로 남음

####1.4.6 훈련 데이터 과소적합
* 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할때 일어남
* 해결 방법
  - 모델 파라미터가 더 많은 모델 선택
  - 더 좋은 특성 제공
  - 모델의 제약을 줄임

####1.4.7 한걸음 물러서서
* 머신러닝의 정의
* 머신러닝의 종류
* 모델 기반일시 모델 파라미터 조정, 사례기반일시 유사도 측정 사용
* 과대적합, 과소적합

###1.5 테스트와 검증
* 훈련 데이터를 훈련 세트와 테스트 세트로 나눔
* 새로운 샘플에 대한 오류 비율을 일반화 오차(generalization error)라 부름
* 테스트 세트에서 모델을 평가함으로써 오차에 대한 추정값을 얻음
* 훈련 오차 < 일반화 오차
  => 훈련 데이터에 과대적합
* 일반화 오차가 적더라도 실제 서비스에서는 오차가 클 수 있음
  - 테스트 세트에 최적화된 하이퍼파라미터와 모델을 만들었기 때문
  - 검증 세트(validation set)를 두어 해결
    - 훈련 세트를 사용해 다양한 하이퍼파라미터로 여러 모델을 훈련
    - 검증 세트에서 최상의 성능을 내는 모델과 하이퍼파라미터 선택
    - 만족스러운 모델을 찾으면 일반화 오차의 추정값을 얻기 위해 테스트 세트로 최종 테스트
  - 훈련 데이터에서 검증 세트로 너무 많은 양의 데이터를 뺏기지 않기 위해 교차검증(cross-validation)기법을 사용
    - 훈련 세트를 여러 서브셋으로 나누고
    - 각 모델을 서브셋의 조합으로 훈련
    - 나머지 부분으로 검증
    - 모델과 하이퍼파라미터가 선택되면
    - 전체 훈련 데이터를 사용하여 최종 모델 훈련
    - 테스트 세트에서 일반화 오차 측정 

###1.6 연습문제